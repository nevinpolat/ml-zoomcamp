{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 10\n",
    "In this homework, we'll deploy the Bank Marketing model from the homework 5. \n",
    "- Building the image\n",
    "- git clone https://github.com/DataTalksClub/machine-learning-zoomcamp.git\n",
    "- Go to the course-zoomcamp/cohorts/2024/05-deployment/homework folder and execute the following:\n",
    "- docker build -t zoomcamp-model:3.11.5-hw10 .\n",
    "Note: If you have troubles building the image, you can use the image we built and published to docker hub: docker pull svizor/zoomcamp-model:3.11.5-hw10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "Run it to test that it's working locally:\n",
    "- docker run -it --rm -p 9696:9696 zoomcamp-model:3.11.5-hw10\n",
    "- python q6_test.py\n",
    "- (base) nevin@np:~/GitHub/machine-learning-zoomcamp/cohorts/2024/05-deployment/homework$ python q6_test.py\n",
    "{'has_subscribed': True, 'has_subscribed_probability': 0.756743795240796}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " <value> is the probability of getting a subscription.\n",
    "- 0.757\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "What's the version of kind that you have?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kind version 0.20.0\n"
     ]
    }
   ],
   "source": [
    "!kind --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a cluster with kind:\n",
    "- kind create cluster\n",
    "And check with kubectl that it was successfully created:\n",
    "\n",
    "- kubectl cluster-info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kubernetes control plane is running at https://127.0.0.1:42129\n",
      "CoreDNS is running at https://127.0.0.1:42129/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\n",
      "\n",
      "To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
     ]
    }
   ],
   "source": [
    "!kubectl cluster-info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "What's the smallest deployable computing unit that we can create and manage in Kubernetes (kind in our case)?\n",
    "- Pod\n",
    "- Pod represents a single instance of a running process in the cluster and can contain one or more containers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "Now let's test if everything works. Use kubectl to get the list of running services.\n",
    "\n",
    "What's the Type of the service that is already running there?\n",
    "- ClusterIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE\n",
      "kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   8m53s\n"
     ]
    }
   ],
   "source": [
    "!kubectl get services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "To be able to use the docker image we previously created (zoomcamp-model:3.11.5-hw10), we need to register it with kind.\n",
    "\n",
    "What's the command we need to run for that?\n",
    "\n",
    "\n",
    "- kind load docker-image\n",
    "- kind load docker-image zoomcamp-model:3.11.5-hw10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "Now let's create a deployment config (e.g. deployment.yaml):\n",
    "\n",
    "- Image Replaced with your Docker image zoomcamp-model:3.11.5-hw10.\n",
    "- Memory (Limits): Set to \"128Mi\" as a reasonable upper limit.\n",
    "- CPU (Limits): Set to \"200m\" to allow for moderate CPU usage.\n",
    "- Port Set to 9696 based on Docker container's exposed port.\n",
    "\n",
    "a219a6fb1916   zoomcamp-model:3.11.5-hw10            \"waitress-serve --liâ€¦\"   8 hours ago      Up 8 hours      0.0.0.0:9696->9696/tcp, :::9696->9696/tcp      \n",
    "                                                                                        cool_lovelace\n",
    "\n",
    "- What is the value for Port?\n",
    "\n",
    "- 9696\n",
    "\n",
    "Apply this deployment using the appropriate command and get a list of running Pods. You can see one running Pod."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps/subscription created\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f deployment.yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                           READY   STATUS    RESTARTS   AGE\n",
      "subscription-86c65486d-9hbhn   1/1     Running   0          23s\n"
     ]
    }
   ],
   "source": [
    "!kubectl get pods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Question 7\n",
    "Fill it in. What do we need to write instead of <???>?\n",
    "\n",
    "- subscription\n",
    "\n",
    "Apply this config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "service/subscription-service created\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f service.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                   TYPE           CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE\n",
      "kubernetes             ClusterIP      10.96.0.1      <none>        443/TCP        54m\n",
      "subscription-service   LoadBalancer   10.96.145.12   <pending>     80:30081/TCP   47s\n"
     ]
    }
   ],
   "source": [
    "!kubectl get services\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the service\n",
    "We can test our service locally by forwarding the port 9696 on our computer to the port 80 on the service:\n",
    "\n",
    "Run q6_test.py (from the homework 5) once again to verify that everything is working. You should get the same result as in Question 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to listen on port 9696: Listeners failed to create with the following errors: [unable to create listener: Error listen tcp4 127.0.0.1:9696: bind: address already in use unable to create listener: Error listen tcp6 [::1]:9696: bind: address already in use]\n",
      "error: unable to listen on any of the requested ports: [{9696 9696}]\n"
     ]
    }
   ],
   "source": [
    "!kubectl port-forward service/subscription-service 9696:80\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forwarding from 127.0.0.1:9697 -> 9696\n",
      "Forwarding from [::1]:9697 -> 9696\n",
      "Handling connection for 9697\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "#We can delete the container or change the port number.  \n",
    "!kubectl port-forward service/subscription-service 9697:80\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'has_subscribed': True, 'has_subscribed_probability': 0.756743795240796}\n"
     ]
    }
   ],
   "source": [
    "!python q6_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoscaling\n",
    "Now we're going to use a HorizontalPodAutoscaler (HPA for short) that automatically updates a workload resource (such as our deployment), with the aim of automatically scaling the workload to match demand.\n",
    "\n",
    "Use the following command to create the HPA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "horizontalpodautoscaler.autoscaling/subscription-hpa autoscaled\n"
     ]
    }
   ],
   "source": [
    "!kubectl autoscale deployment subscription --name subscription-hpa --cpu-percent=20 --min=1 --max=3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME               REFERENCE                 TARGETS         MINPODS   MAXPODS   REPLICAS   AGE\n",
      "subscription-hpa   Deployment/subscription   <unknown>/20%   1         3         1          18s\n"
     ]
    }
   ],
   "source": [
    "!kubectl get hpa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Increase the load\n",
    "Let's see how the autoscaler reacts to increasing the load. To do this, we can slightly modify the existing q6_test.py script by putting the operator that sends the request to the subscription service into a loop.\n",
    "\n",
    "while True:\n",
    "    sleep(0.1)\n",
    "    response = requests.post(url, json=client).json()\n",
    "    print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8 (optional)\n",
    "Run kubectl get hpa subscription-hpa --watch command to monitor how the autoscaler performs. Within a minute or so, you should see the higher CPU load; and then - more replicas. What was the maximum amount of the replicas during this test?\n",
    "\n",
    "- 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME               REFERENCE                 TARGETS   MINPODS   MAXPODS   REPLICAS   AGE\n",
      "subscription-hpa   Deployment/subscription   1%/20%    1         3         1          81m\n",
      "subscription-hpa   Deployment/subscription   6%/20%    1         3         1          81m\n",
      "subscription-hpa   Deployment/subscription   19%/20%   1         3         1          82m\n",
      "subscription-hpa   Deployment/subscription   20%/20%   1         3         1          82m\n",
      "subscription-hpa   Deployment/subscription   19%/20%   1         3         1          82m\n",
      "subscription-hpa   Deployment/subscription   20%/20%   1         3         1          82m\n",
      "subscription-hpa   Deployment/subscription   6%/20%    1         3         1          83m\n",
      "subscription-hpa   Deployment/subscription   1%/20%    1         3         1          83m\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!kubectl get hpa subscription-hpa --watch\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "week9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
